{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "\n",
    "from functools import reduce  # For Python 3.x\n",
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"unionjointest\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000) \\\n",
    "  ]\n",
    "\n",
    "columns= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData2 = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "  ]\n",
    "columns2= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "\n",
    "df2 = spark.createDataFrame(data = simpleData2, schema = columns2)\n",
    "\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df.union(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unionAllDF = df.unionAll(df2)\n",
    "unionAllDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_union = df.union(df2).distinct()\n",
    "df_union.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_union_drop = df.union(df2).dropDuplicates()\n",
    "df_union_drop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_union1 = df.union(df2).union(df3)\n",
    "df_union1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def unionAll(*dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs)\n",
    "\n",
    "df5 = unionAll(df, df2, df3)\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 3, 1, 1, 2, 3]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd_union\n",
    "rdd = spark.sparkContext.parallelize([1, 1, 2, 3])\n",
    "rdd.union(rdd).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "34\n",
      "+----------+------------+-----+\n",
      "|       _c0|         _c1|  _c2|\n",
      "+----------+------------+-----+\n",
      "|product_id|product_name|price|\n",
      "|         0|   product_0|   22|\n",
      "|         1|   product_1|   30|\n",
      "|         2|   product_2|   91|\n",
      "|         3|   product_3|   37|\n",
      "|         4|   product_4|  145|\n",
      "|         5|   product_5|  128|\n",
      "|         6|   product_6|   66|\n",
      "|         7|   product_7|  145|\n",
      "|         8|   product_8|   51|\n",
      "|         9|   product_9|   44|\n",
      "|        10|  product_10|   53|\n",
      "|        11|  product_11|   13|\n",
      "|        12|  product_12|  104|\n",
      "|        13|  product_13|  102|\n",
      "|        14|  product_14|   24|\n",
      "|        15|  product_15|   14|\n",
      "|        16|  product_16|   38|\n",
      "|        17|  product_17|   72|\n",
      "|        18|  product_18|   16|\n",
      "+----------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product = spark.read.csv(\"./products.csv\")\n",
    "print(product.rdd.getNumPartitions())\n",
    "productdup = product.union(product)\n",
    "print(productdup.rdd.getNumPartitions())\n",
    "productdup.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "+----------+------------+-----+\n",
      "|product_id|product_name|price|\n",
      "+----------+------------+-----+\n",
      "|         0|   product_0|   22|\n",
      "|         1|   product_1|   30|\n",
      "|         2|   product_2|   91|\n",
      "|         3|   product_3|   37|\n",
      "|         4|   product_4|  145|\n",
      "|         5|   product_5|  128|\n",
      "|         6|   product_6|   66|\n",
      "|         7|   product_7|  145|\n",
      "|         8|   product_8|   51|\n",
      "|         9|   product_9|   44|\n",
      "|        10|  product_10|   53|\n",
      "|        11|  product_11|   13|\n",
      "|        12|  product_12|  104|\n",
      "|        13|  product_13|  102|\n",
      "|        14|  product_14|   24|\n",
      "|        15|  product_15|   14|\n",
      "|        16|  product_16|   38|\n",
      "|        17|  product_17|   72|\n",
      "|        18|  product_18|   16|\n",
      "|        19|  product_19|   46|\n",
      "+----------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product = spark.read.parquet(\"./products_parquet\")\n",
    "print(product.rdd.getNumPartitions())\n",
    "product.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "+----------+----------------+-----+----------------+-----+\n",
      "|product_id|    product_name|price|    product_name|price|\n",
      "+----------+----------------+-----+----------------+-----+\n",
      "|  10000108|product_10000108|  115|product_10000108|  115|\n",
      "|  10000172|product_10000172|  133|product_10000172|  133|\n",
      "|  10000304|product_10000304|   71|product_10000304|   71|\n",
      "|  10000454|product_10000454|  135|product_10000454|  135|\n",
      "|  10000472|product_10000472|   62|product_10000472|   62|\n",
      "|  10000528|product_10000528|  122|product_10000528|  122|\n",
      "|  10000591|product_10000591|   23|product_10000591|   23|\n",
      "|  10000670|product_10000670|   30|product_10000670|   30|\n",
      "|  10000720|product_10000720|  118|product_10000720|  118|\n",
      "|  10000723|product_10000723|   92|product_10000723|   92|\n",
      "|  10000761|product_10000761|  124|product_10000761|  124|\n",
      "|  10000835|product_10000835|   74|product_10000835|   74|\n",
      "|  10000989|product_10000989|    8|product_10000989|    8|\n",
      "|    100010|  product_100010|   98|  product_100010|   98|\n",
      "|  10001331|product_10001331|   10|product_10001331|   10|\n",
      "|  10001922|product_10001922|   96|product_10001922|   96|\n",
      "|  10001989|product_10001989|   13|product_10001989|   13|\n",
      "|  10002011|product_10002011|   31|product_10002011|   31|\n",
      "|  10002280|product_10002280|   17|product_10002280|   17|\n",
      "|   1000240| product_1000240|   66| product_1000240|   66|\n",
      "+----------+----------------+-----+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "productdup = product.join(product, on = \"product_id\", how = \"inner\")\n",
    "print(productdup.rdd.getNumPartitions())\n",
    "productdup.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heroes_data = [\n",
    "    ('Deadpool', 3), \n",
    "    ('Iron man', 1),\n",
    "    ('Groot', 7),\n",
    "]\n",
    "race_data = [\n",
    "    ('Kryptonian', 5), \n",
    "    ('Mutant', 3), \n",
    "    ('Human', 1), \n",
    "]\n",
    "heroes = spark.createDataFrame(heroes_data, ['name', 'id'])\n",
    "races = spark.createDataFrame(race_data, ['race', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    name| id|\n",
      "+--------+---+\n",
      "|Deadpool|  3|\n",
      "|Iron man|  1|\n",
      "|   Groot|  7|\n",
      "+--------+---+\n",
      "\n",
      "+----------+---+\n",
      "|      race| id|\n",
      "+----------+---+\n",
      "|Kryptonian|  5|\n",
      "|    Mutant|  3|\n",
      "|     Human|  1|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.show()\n",
    "races.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+---+\n",
      "|    name| id|      race| id|\n",
      "+--------+---+----------+---+\n",
      "|Deadpool|  3|Kryptonian|  5|\n",
      "|Deadpool|  3|    Mutant|  3|\n",
      "|Deadpool|  3|     Human|  1|\n",
      "|Iron man|  1|Kryptonian|  5|\n",
      "|Iron man|  1|    Mutant|  3|\n",
      "|Iron man|  1|     Human|  1|\n",
      "|   Groot|  7|Kryptonian|  5|\n",
      "|   Groot|  7|    Mutant|  3|\n",
      "|   Groot|  7|     Human|  1|\n",
      "+--------+---+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.crossJoin(races).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+--------+---+\n",
      "|    name| id|    name| id|\n",
      "+--------+---+--------+---+\n",
      "|Deadpool|  3|Deadpool|  3|\n",
      "|Deadpool|  3|Iron man|  1|\n",
      "|Deadpool|  3|   Groot|  7|\n",
      "|Iron man|  1|Deadpool|  3|\n",
      "|Iron man|  1|Iron man|  1|\n",
      "|Iron man|  1|   Groot|  7|\n",
      "|   Groot|  7|Deadpool|  3|\n",
      "|   Groot|  7|Iron man|  1|\n",
      "|   Groot|  7|   Groot|  7|\n",
      "+--------+---+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(heroes).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+\n",
      "| id|    name|    name|\n",
      "+---+--------+--------+\n",
      "|  7|   Groot|   Groot|\n",
      "|  1|Iron man|Iron man|\n",
      "|  3|Deadpool|Deadpool|\n",
      "+---+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(heroes, on = \"id\", how = 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|  race|\n",
      "+---+--------+------+\n",
      "|  1|Iron man| Human|\n",
      "|  3|Deadpool|Mutant|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(races, on = \"id\", how = 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+---+\n",
      "|    name| id|      race| id|\n",
      "+--------+---+----------+---+\n",
      "|Deadpool|  3|Kryptonian|  5|\n",
      "|Deadpool|  3|    Mutant|  3|\n",
      "|Deadpool|  3|     Human|  1|\n",
      "|Iron man|  1|Kryptonian|  5|\n",
      "|Iron man|  1|    Mutant|  3|\n",
      "|Iron man|  1|     Human|  1|\n",
      "|   Groot|  7|Kryptonian|  5|\n",
      "|   Groot|  7|    Mutant|  3|\n",
      "|   Groot|  7|     Human|  1|\n",
      "+--------+---+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(races).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding a new row to a dataframe\n",
    "newrow = spark.createDataFrame([('Iron man', 1)], ['name', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    name| id|\n",
      "+--------+---+\n",
      "|Deadpool|  3|\n",
      "|Iron man|  1|\n",
      "|   Groot|  7|\n",
      "|Iron man|  1|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes_new = heroes.union(newrow)\n",
    "heroes_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|  race|\n",
      "+---+--------+------+\n",
      "|  1|Iron man| Human|\n",
      "|  1|Iron man| Human|\n",
      "|  3|Deadpool|Mutant|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inner join don't remove duplicates\n",
    "heroes_new.join(races, on = \"id\", how = 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|  race|\n",
      "+---+--------+------+\n",
      "|  7|   Groot|  null|\n",
      "|  1|Iron man| Human|\n",
      "|  3|Deadpool|Mutant|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(races, on = \"id\", how = 'left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+\n",
      "| id|    name|  race|\n",
      "+---+--------+------+\n",
      "|  7|   Groot|  null|\n",
      "|  1|Iron man| Human|\n",
      "|  3|Deadpool|Mutant|\n",
      "+---+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(races, on = \"id\", how = 'leftouter').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+\n",
      "| id|    name|      race|\n",
      "+---+--------+----------+\n",
      "|  5|    null|Kryptonian|\n",
      "|  1|Iron man|     Human|\n",
      "|  3|Deadpool|    Mutant|\n",
      "+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(races, on='id', how='right').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+\n",
      "| id|    name|      race|\n",
      "+---+--------+----------+\n",
      "|  5|    null|Kryptonian|\n",
      "|  1|Iron man|     Human|\n",
      "|  3|Deadpool|    Mutant|\n",
      "+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(races, on='id', how='rightouter').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+\n",
      "| id|    name|      race|\n",
      "+---+--------+----------+\n",
      "|  7|   Groot|      null|\n",
      "|  5|    null|Kryptonian|\n",
      "|  1|Iron man|     Human|\n",
      "|  3|Deadpool|    Mutant|\n",
      "+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(races, on='id', how='full').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+\n",
      "| id|    name|      race|\n",
      "+---+--------+----------+\n",
      "|  7|   Groot|      null|\n",
      "|  5|    null|Kryptonian|\n",
      "|  1|Iron man|     Human|\n",
      "|  3|Deadpool|    Mutant|\n",
      "+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(races, on='id', how='outer').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|    name|\n",
      "+---+--------+\n",
      "|  1|Iron man|\n",
      "|  3|Deadpool|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(races, on='id', how='leftsemi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  7|Groot|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heroes.join(races, on='id', how='leftanti').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Join with Bradcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|     city|\n",
      "+----------+---------+\n",
      "|    andrea| medellin|\n",
      "|   rodolfo| medellin|\n",
      "|     abdul|bangalore|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF = spark.createDataFrame(data = [(\"andrea\", \"medellin\"), (\"rodolfo\", \"medellin\"), (\"abdul\", \"bangalore\")], schema = [\"first_name\", \"city\"])\n",
    "peopleDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|     city|\n",
      "+----------+---------+\n",
      "|    andrea| medellin|\n",
      "|   rodolfo| medellin|\n",
      "|     abdul|bangalore|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF = spark.sparkContext.parallelize([(\"andrea\", \"medellin\"), (\"rodolfo\", \"medellin\"), (\"abdul\", \"bangalore\")]) \\\n",
    "           .toDF((\"first_name\", \"city\"))\n",
    "peopleDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+\n",
      "|     city| country|population|\n",
      "+---------+--------+----------+\n",
      "| medellin|colombia|       2.5|\n",
      "|bangalore|   india|      12.3|\n",
      "+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citiesDF = spark.sparkContext.parallelize([(\"medellin\", \"colombia\", 2.5), (\"bangalore\", \"india\", 12.3)]) \\\n",
    "           .toDF((\"city\", \"country\", \"population\"))\n",
    "citiesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+\n",
      "|     city|first_name| country|population|\n",
      "+---------+----------+--------+----------+\n",
      "|bangalore|     abdul|   india|      12.3|\n",
      "| medellin|    andrea|colombia|       2.5|\n",
      "| medellin|   rodolfo|colombia|       2.5|\n",
      "+---------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF.join(citiesDF, on = 'city').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [city#3846, first_name#3845, country#3859, population#3860]\n",
      "+- *(5) SortMergeJoin [city#3846], [city#3858], Inner\n",
      "   :- *(2) Sort [city#3846 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(city#3846, 200), true, [id=#5431]\n",
      "   :     +- *(1) Filter isnotnull(city#3846)\n",
      "   :        +- *(1) Scan ExistingRDD[first_name#3845,city#3846]\n",
      "   +- *(4) Sort [city#3858 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(city#3858, 200), true, [id=#5437]\n",
      "         +- *(3) Filter isnotnull(city#3858)\n",
      "            +- *(3) Scan ExistingRDD[city#3858,country#3859,population#3860]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF.join(citiesDF, on = 'city').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+\n",
      "|     city|first_name| country|population|\n",
      "+---------+----------+--------+----------+\n",
      "| medellin|    andrea|colombia|       2.5|\n",
      "| medellin|   rodolfo|colombia|       2.5|\n",
      "|bangalore|     abdul|   india|      12.3|\n",
      "+---------+----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "peopleDF.join(broadcast(citiesDF), on = 'city').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+--------+----------+\n",
      "|first_name|     city|     city| country|population|\n",
      "+----------+---------+---------+--------+----------+\n",
      "|    andrea| medellin| medellin|colombia|       2.5|\n",
      "|   rodolfo| medellin| medellin|colombia|       2.5|\n",
      "|     abdul|bangalore|bangalore|   india|      12.3|\n",
      "+----------+---------+---------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import broadcast\n",
    "# peopleDF.join(broadcast(citiesDF), (peopleDF.city == citiesDF.city)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Join UsingJoin(Inner,Buffer(city))\n",
      ":- LogicalRDD [first_name#3845, city#3846], false\n",
      "+- ResolvedHint (strategy=broadcast)\n",
      "   +- LogicalRDD [city#3858, country#3859, population#3860], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "city: string, first_name: string, country: string, population: double\n",
      "Project [city#3846, first_name#3845, country#3859, population#3860]\n",
      "+- Join Inner, (city#3846 = city#3858)\n",
      "   :- LogicalRDD [first_name#3845, city#3846], false\n",
      "   +- ResolvedHint (strategy=broadcast)\n",
      "      +- LogicalRDD [city#3858, country#3859, population#3860], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [city#3846, first_name#3845, country#3859, population#3860]\n",
      "+- Join Inner, (city#3846 = city#3858), rightHint=(strategy=broadcast)\n",
      "   :- Filter isnotnull(city#3846)\n",
      "   :  +- LogicalRDD [first_name#3845, city#3846], false\n",
      "   +- Filter isnotnull(city#3858)\n",
      "      +- LogicalRDD [city#3858, country#3859, population#3860], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) Project [city#3846, first_name#3845, country#3859, population#3860]\n",
      "+- *(2) BroadcastHashJoin [city#3846], [city#3858], Inner, BuildRight\n",
      "   :- *(2) Filter isnotnull(city#3846)\n",
      "   :  +- *(2) Scan ExistingRDD[first_name#3845,city#3846]\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false])), [id=#5578]\n",
      "      +- *(1) Filter isnotnull(city#3858)\n",
      "         +- *(1) Scan ExistingRDD[city#3858,country#3859,population#3860]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF.join(broadcast(citiesDF), on = 'city').explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_data = [\n",
    "    ('Deadpool', 3), \n",
    "    ('Iron man', 1),\n",
    "    ('Groot', 7),\n",
    "]\n",
    "race_data = [\n",
    "    ('Kryptonian', 5), \n",
    "    ('Mutant', 3), \n",
    "    ('Human', 1), \n",
    "]\n",
    "heroes = spark.createDataFrame(heroes_data, ['name', 'id'])\n",
    "races = spark.createDataFrame(race_data, ['race', 'id_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    name| id|\n",
      "+--------+---+\n",
      "|Deadpool|  3|\n",
      "|Iron man|  1|\n",
      "|   Groot|  7|\n",
      "+--------+---+\n",
      "\n",
      "None\n",
      "+----------+----+\n",
      "|      race|id_b|\n",
      "+----------+----+\n",
      "|Kryptonian|   5|\n",
      "|    Mutant|   3|\n",
      "|     Human|   1|\n",
      "+----------+----+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(heroes.show())\n",
    "print(races.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+----+\n",
      "|    name| id|  race|id_b|\n",
      "+--------+---+------+----+\n",
      "|Iron man|  1| Human|   1|\n",
      "|Deadpool|  3|Mutant|   3|\n",
      "+--------+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = heroes.join(races, heroes[\"id\"] == races[\"id_b\"], how = \"inner\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = [\n",
    "    (123, 1), \n",
    "    (456, 2),\n",
    "    (111, 3),\n",
    "    (678, 4),\n",
    "]\n",
    "\n",
    "data2 = [\n",
    "    (456, 2), \n",
    "    (111, 3), \n",
    "    (876, 4), \n",
    "]\n",
    "\n",
    "i = spark.createDataFrame(data1, ['COL_A', 'ID'])\n",
    "j = spark.createDataFrame(data2, ['COL_B', 'ID_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|COL_A| ID|\n",
      "+-----+---+\n",
      "|  123|  1|\n",
      "|  456|  2|\n",
      "|  111|  3|\n",
      "|  678|  4|\n",
      "+-----+---+\n",
      "\n",
      "None\n",
      "+-----+----+\n",
      "|COL_B|ID_B|\n",
      "+-----+----+\n",
      "|  456|   2|\n",
      "|  111|   3|\n",
      "|  876|   4|\n",
      "+-----+----+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(i.show())\n",
    "print(j.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|COL_A| ID|\n",
      "+-----+---+\n",
      "|  123|  1|\n",
      "|  678|  4|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i.subtract(j).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+----+\n",
      "|COL_A| ID|COL_B|ID_B|\n",
      "+-----+---+-----+----+\n",
      "|  678|  4| null|null|\n",
      "|  111|  3|  111|   3|\n",
      "|  123|  1| null|null|\n",
      "|  456|  2|  456|   2|\n",
      "+-----+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "left_join = i.join(j, j[\"COL_B\"] == i[\"COL_A\"],how='left')\n",
    "left_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|COL_A| ID|\n",
      "+-----+---+\n",
      "|  678|  4|\n",
      "|  123|  1|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "left_join = left_join.filter(left_join[\"COL_B\"].isNull()).select('COL_A', 'ID')\n",
    "left_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = [\n",
    "    (123, 1), \n",
    "    (456, 2),\n",
    "    (111, 3),\n",
    "    (678, 4),\n",
    "]\n",
    "\n",
    "data2 = [\n",
    "    (981, 2), \n",
    "    (876, 5), \n",
    "]\n",
    "\n",
    "i = spark.createDataFrame(data1, ['COL_A', 'ID'])\n",
    "j = spark.createDataFrame(data2, ['COL_B', 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|COL_A| ID|\n",
      "+-----+---+\n",
      "|  123|  1|\n",
      "|  456|  2|\n",
      "|  111|  3|\n",
      "|  678|  4|\n",
      "+-----+---+\n",
      "\n",
      "None\n",
      "+-----+---+\n",
      "|COL_B| ID|\n",
      "+-----+---+\n",
      "|  981|  2|\n",
      "|  876|  5|\n",
      "+-----+---+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(i.show())\n",
    "print(j.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|COL_A| ID|\n",
      "+-----+---+\n",
      "|  123|  1|\n",
      "|  456|  2|\n",
      "|  111|  3|\n",
      "|  678|  4|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i.subtract(j).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| ID|COL_A|COL_B|\n",
      "+---+-----+-----+\n",
      "|  5| null|  876|\n",
      "|  1|  123| null|\n",
      "|  3|  111| null|\n",
      "|  2|  456|  981|\n",
      "|  4|  678| null|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fulljoin = i.join(j, on = \"ID\", how = \"full\")\n",
    "fulljoin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| ID|COL_A|COL_B|\n",
      "+---+-----+-----+\n",
      "|  5| null|  876|\n",
      "|  2|  456|  981|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fulljoin.filter(fulljoin[\"COL_B\"].isNull() == False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
